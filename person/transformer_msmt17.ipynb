{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "beaeecf3-2a01-454b-932c-3ec0e0b4386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Untitled.ipynb\t __MACOSX\t      onstart.sh\n",
      "Untitled1.ipynb  msmt17_combined      ports.log\n",
      "Untitled2.ipynb  msmt17_combined.zip  tensorflow-tutorials\n"
     ]
    }
   ],
   "source": [
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1edc97eb-d972-4454-81f8-c46270f2e252",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-10-14 00:32:26.241215: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-10-14 00:32:26.255235: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-10-14 00:32:26.270369: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-10-14 00:32:26.275295: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-10-14 00:32:26.287738: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F AVX512_VNNI AVX512_BF16 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CUDA device: NVIDIA H100 NVL\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.11/dist-packages/transformers/models/vit/feature_extraction_vit.py:28: FutureWarning: The class ViTFeatureExtractor is deprecated and will be removed in version 5 of Transformers. Please use ViTImageProcessor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unfroze 30/200 layers.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_7248/3945453519.py:111: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = GradScaler()\n",
      "Epoch 1/30:   0%|          | 0/1976 [00:00<?, ?it/s]/tmp/ipykernel_7248/3945453519.py:154: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with autocast():\n",
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30 completed in 948.80 seconds\n",
      "Epoch 1/30, Average Loss: 0.0681\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/30 completed in 974.90 seconds\n",
      "Epoch 2/30, Average Loss: 0.0334\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 3/30 completed in 981.13 seconds\n",
      "Epoch 3/30, Average Loss: 0.0271\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/30 completed in 979.68 seconds\n",
      "Epoch 4/30, Average Loss: 0.0230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 5/30 completed in 968.41 seconds\n",
      "Epoch 5/30, Average Loss: 0.0202\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6/30 completed in 956.23 seconds\n",
      "Epoch 6/30, Average Loss: 0.0273\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 7/30 completed in 989.92 seconds\n",
      "Epoch 7/30, Average Loss: 0.0259\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 8/30 completed in 980.24 seconds\n",
      "Epoch 8/30, Average Loss: 0.0238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                            \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 9/30 completed in 985.79 seconds\n",
      "Epoch 9/30, Average Loss: 0.0223\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10/30 completed in 979.88 seconds\n",
      "Epoch 10/30, Average Loss: 0.0204\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 11/30 completed in 965.45 seconds\n",
      "Epoch 11/30, Average Loss: 0.0190\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/30 completed in 970.64 seconds\n",
      "Epoch 12/30, Average Loss: 0.0169\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 13/30 completed in 950.57 seconds\n",
      "Epoch 13/30, Average Loss: 0.0158\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 14/30 completed in 982.05 seconds\n",
      "Epoch 14/30, Average Loss: 0.0147\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 15/30 completed in 970.20 seconds\n",
      "Epoch 15/30, Average Loss: 0.0137\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 16/30 completed in 921.61 seconds\n",
      "Epoch 16/30, Average Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 17/30 completed in 926.76 seconds\n",
      "Epoch 17/30, Average Loss: 0.0225\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/30 completed in 966.09 seconds\n",
      "Epoch 18/30, Average Loss: 0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 19/30 completed in 969.09 seconds\n",
      "Epoch 19/30, Average Loss: 0.0222\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 20/30 completed in 956.18 seconds\n",
      "Epoch 20/30, Average Loss: 0.0216\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/30 completed in 991.70 seconds\n",
      "Epoch 21/30, Average Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 22/30 completed in 999.11 seconds\n",
      "Epoch 22/30, Average Loss: 0.0206\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 23/30 completed in 974.53 seconds\n",
      "Epoch 23/30, Average Loss: 0.0193\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 24/30 completed in 942.98 seconds\n",
      "Epoch 24/30, Average Loss: 0.0191\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 25/30 completed in 991.31 seconds\n",
      "Epoch 25/30, Average Loss: 0.0177\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 26/30 completed in 980.22 seconds\n",
      "Epoch 26/30, Average Loss: 0.0170\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 27/30 completed in 977.25 seconds\n",
      "Epoch 27/30, Average Loss: 0.0159\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 28/30 completed in 977.12 seconds\n",
      "Epoch 28/30, Average Loss: 0.0155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 29/30 completed in 971.22 seconds\n",
      "Epoch 29/30, Average Loss: 0.0135\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                             \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 30/30 completed in 774.02 seconds\n",
      "Epoch 30/30, Average Loss: 0.0135\n",
      "Training completed!\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.optim.lr_scheduler import StepLR, CosineAnnealingWarmRestarts\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import ViTModel, ViTFeatureExtractor\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import random\n",
    "import numpy as np\n",
    "from torch.nn import TripletMarginLoss\n",
    "from torch.cuda.amp import autocast, GradScaler  # For mixed-precision training\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Parameters\n",
    "IMG_SIZE = 224\n",
    "BATCH_SIZE = 64\n",
    "EPOCHS = 30\n",
    "EMBEDDING_DIM = 512\n",
    "INITIAL_LR = 1e-4\n",
    "MARGIN = 0.3  # Triplet loss margin\n",
    "DROPOUT_PROB = 0.3\n",
    "WEIGHT_DECAY = 1e-5\n",
    "\n",
    "# Ensure reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Check for CUDA availability\n",
    "if torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "    print(f\"Using CUDA device: {torch.cuda.get_device_name(0)}\")\n",
    "else:\n",
    "    raise RuntimeError(\"This script requires a CUDA-enabled GPU to run.\")\n",
    "\n",
    "# Preprocessing\n",
    "feature_extractor = ViTFeatureExtractor.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "\n",
    "class TripletDataset(Dataset):\n",
    "    def __init__(self, image_paths, labels):\n",
    "        self.image_paths = image_paths\n",
    "        self.labels = labels\n",
    "        self.transform = transforms.Compose([\n",
    "            transforms.Resize((IMG_SIZE, IMG_SIZE)),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomApply([transforms.ColorJitter(0.3, 0.3, 0.3, 0.1)], p=0.5),\n",
    "            transforms.RandomApply([transforms.GaussianBlur(3)], p=0.2),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.5, 0.5, 0.5], std=[0.5, 0.5, 0.5])\n",
    "        ])\n",
    "        self.label_to_indices = {label: np.where(np.array(labels) == label)[0].tolist() for label in set(labels)}\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        anchor_path = self.image_paths[index]\n",
    "        anchor_label = self.labels[index]\n",
    "\n",
    "        # Positive and negative mining logic\n",
    "        positive_index = random.choice(self.label_to_indices[anchor_label])\n",
    "        while positive_index == index:\n",
    "            positive_index = random.choice(self.label_to_indices[anchor_label])\n",
    "        positive_path = self.image_paths[positive_index]\n",
    "\n",
    "        negative_label = random.choice(list(set(self.labels) - {anchor_label}))\n",
    "        negative_index = random.choice(self.label_to_indices[negative_label])\n",
    "        negative_path = self.image_paths[negative_index]\n",
    "\n",
    "        anchor = self.transform(Image.open(anchor_path).convert('RGB'))\n",
    "        positive = self.transform(Image.open(positive_path).convert('RGB'))\n",
    "        negative = self.transform(Image.open(negative_path).convert('RGB'))\n",
    "\n",
    "        return anchor, positive, negative, anchor_label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "# Model definition with dropout\n",
    "class PersonReIDTransformer(nn.Module):\n",
    "    def __init__(self, embedding_dim=512, dropout_prob=0.3):\n",
    "        super(PersonReIDTransformer, self).__init__()\n",
    "        self.backbone = ViTModel.from_pretrained('google/vit-base-patch16-224-in21k')\n",
    "        self.embedding = nn.Sequential(\n",
    "            nn.Linear(self.backbone.config.hidden_size, embedding_dim),\n",
    "            nn.Dropout(p=dropout_prob)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        outputs = self.backbone(x).last_hidden_state[:, 0]\n",
    "        embeddings = self.embedding(outputs)\n",
    "        return embeddings\n",
    "\n",
    "# Initialize model\n",
    "model = PersonReIDTransformer(dropout_prob=DROPOUT_PROB).to(device)\n",
    "\n",
    "# Unfreeze layers for fine-tuning\n",
    "def unfreeze_layers(model, percentage_unfrozen):\n",
    "    total_layers = len(list(model.backbone.parameters()))\n",
    "    unfreeze_count = int(total_layers * percentage_unfrozen)\n",
    "    for i, param in enumerate(model.backbone.parameters()):\n",
    "        if i < unfreeze_count:\n",
    "            param.requires_grad = True\n",
    "        else:\n",
    "            param.requires_grad = False\n",
    "    print(f\"Unfroze {unfreeze_count}/{total_layers} layers.\")\n",
    "\n",
    "unfreeze_layers(model, 0.15)\n",
    "\n",
    "# Mixed precision\n",
    "scaler = GradScaler()\n",
    "\n",
    "# Triplet Loss function\n",
    "criterion = TripletMarginLoss(margin=MARGIN)\n",
    "\n",
    "# Optimizer and learning rate scheduler\n",
    "optimizer = optim.Adam(model.parameters(), lr=INITIAL_LR, weight_decay=WEIGHT_DECAY)\n",
    "scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=5, T_mult=2, eta_min=1e-6)\n",
    "\n",
    "# Load the dataset paths and labels\n",
    "def get_image_paths_and_labels(root_dir):\n",
    "    image_paths = []\n",
    "    labels = []\n",
    "    for person_id in os.listdir(root_dir):\n",
    "        person_dir = os.path.join(root_dir, person_id)\n",
    "        if os.path.isdir(person_dir):\n",
    "            for image_name in os.listdir(person_dir):\n",
    "                if image_name.endswith('.jpg'):\n",
    "                    image_paths.append(os.path.join(person_dir, image_name))\n",
    "                    labels.append(int(person_id))\n",
    "    return image_paths, labels\n",
    "\n",
    "# Load data\n",
    "train_paths, train_labels = get_image_paths_and_labels(\"./msmt17_combined/train\")\n",
    "dataset = TripletDataset(train_paths, train_labels)\n",
    "data_loader = DataLoader(dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "\n",
    "# Training loop with mixed precision\n",
    "model.train()\n",
    "total_batches = len(data_loader)\n",
    "for epoch in range(EPOCHS):\n",
    "    epoch_loss = 0\n",
    "    start_time = time.time()\n",
    "    \n",
    "    progress_bar = tqdm(data_loader, desc=f\"Epoch {epoch+1}/{EPOCHS}\", leave=False)\n",
    "    \n",
    "    for batch_idx, batch in enumerate(progress_bar):\n",
    "        anchor, positive, negative, labels = batch\n",
    "        anchor, positive, negative = anchor.to(device), positive.to(device), negative.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Mixed precision training\n",
    "        with autocast():\n",
    "            anchor_embedding = model(anchor)\n",
    "            positive_embedding = model(positive)\n",
    "            negative_embedding = model(negative)\n",
    "\n",
    "            loss = criterion(anchor_embedding, positive_embedding, negative_embedding)\n",
    "\n",
    "        scaler.scale(loss).backward()\n",
    "        scaler.step(optimizer)\n",
    "        scaler.update()\n",
    "\n",
    "        epoch_loss += loss.item()\n",
    "\n",
    "        # Update progress bar\n",
    "        progress_bar.set_postfix({'Loss': f\"{loss.item():.4f}\"})\n",
    "\n",
    "    scheduler.step()\n",
    "    epoch_time = time.time() - start_time\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS} completed in {epoch_time:.2f} seconds\")\n",
    "    print(f\"Epoch {epoch+1}/{EPOCHS}, Average Loss: {epoch_loss / total_batches:.4f}\")\n",
    "\n",
    "    # Optional: Save model checkpoint after each epoch\n",
    "    torch.save(model.state_dict(), f'person_reid_model_vit_msmt17_epoch_{epoch+1}.pth')\n",
    "\n",
    "print(\"Training completed!\")\n",
    "torch.save(model.state_dict(), 'person_reid_model_vit_msmt17_final.pth')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c1d8324-c4c8-4e2d-9a10-57713dc891e1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0rc1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
